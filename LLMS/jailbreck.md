Obviously during implementation. make sure you also have some logging mechanism. Here are some repositories which you might want to consider for Testing & Monitoring. 




 

https://github.com/utkusen/promptmap

https://github.com/preset-io/promptimize

https://github.com/Cranot/chatbot-injections-exploits

https://github.com/leondz/garak/

https://github.com/whylabs/langkit

https://shreyar.github.io/guardrails/#rail-spec

https://github.com/ianarawjo/ChainForge/

https://learnprompting.org/docs/category/-defensive-measures - some methods to be used for (meta)prompt construction.

 

Microsoft log prompts & more:

https://github.com/Azure-Samples/openai-python-enterprise-logging & of course PromptFlow

 

So I guess Testing + Monitoring + careful Prompt Engineering will minimize the attack surface, but of course never full proof.